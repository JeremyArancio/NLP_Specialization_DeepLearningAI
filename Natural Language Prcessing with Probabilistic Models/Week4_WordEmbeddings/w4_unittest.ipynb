{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from numpy.lib.shape_base import expand_dims\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from utils2 import sigmoid, get_batches, compute_pca, get_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_initialize_model(target):\n",
    "    successful_cases = 0\n",
    "    failed_cases = []\n",
    "\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"name\": \"default_check\",\n",
    "            \"input\": {\"N\": 4, \"V\": 10, \"random_seed\": 1},\n",
    "            \"expected\": {\n",
    "                \"w1\": np.array(\n",
    "                    [\n",
    "                        [\n",
    "                            4.17022005e-01,\n",
    "                            7.20324493e-01,\n",
    "                            1.14374817e-04,\n",
    "                            3.02332573e-01,\n",
    "                            1.46755891e-01,\n",
    "                            9.23385948e-02,\n",
    "                            1.86260211e-01,\n",
    "                            3.45560727e-01,\n",
    "                            3.96767474e-01,\n",
    "                            5.38816734e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            4.19194514e-01,\n",
    "                            6.85219500e-01,\n",
    "                            2.04452250e-01,\n",
    "                            8.78117436e-01,\n",
    "                            2.73875932e-02,\n",
    "                            6.70467510e-01,\n",
    "                            4.17304802e-01,\n",
    "                            5.58689828e-01,\n",
    "                            1.40386939e-01,\n",
    "                            1.98101489e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            8.00744569e-01,\n",
    "                            9.68261576e-01,\n",
    "                            3.13424178e-01,\n",
    "                            6.92322616e-01,\n",
    "                            8.76389152e-01,\n",
    "                            8.94606664e-01,\n",
    "                            8.50442114e-02,\n",
    "                            3.90547832e-02,\n",
    "                            1.69830420e-01,\n",
    "                            8.78142503e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            9.83468338e-02,\n",
    "                            4.21107625e-01,\n",
    "                            9.57889530e-01,\n",
    "                            5.33165285e-01,\n",
    "                            6.91877114e-01,\n",
    "                            3.15515631e-01,\n",
    "                            6.86500928e-01,\n",
    "                            8.34625672e-01,\n",
    "                            1.82882773e-02,\n",
    "                            7.50144315e-01,\n",
    "                        ],\n",
    "                    ]\n",
    "                ),\n",
    "                \"w2\": np.array(\n",
    "                    [\n",
    "                        [0.98886109, 0.74816565, 0.28044399, 0.78927933],\n",
    "                        [0.10322601, 0.44789353, 0.9085955, 0.29361415],\n",
    "                        [0.28777534, 0.13002857, 0.01936696, 0.67883553],\n",
    "                        [0.21162812, 0.26554666, 0.49157316, 0.05336255],\n",
    "                        [0.57411761, 0.14672857, 0.58930554, 0.69975836],\n",
    "                        [0.10233443, 0.41405599, 0.69440016, 0.41417927],\n",
    "                        [0.04995346, 0.53589641, 0.66379465, 0.51488911],\n",
    "                        [0.94459476, 0.58655504, 0.90340192, 0.1374747],\n",
    "                        [0.13927635, 0.80739129, 0.39767684, 0.1653542],\n",
    "                        [0.92750858, 0.34776586, 0.7508121, 0.72599799],\n",
    "                    ]\n",
    "                ),\n",
    "                \"b1\": np.array(\n",
    "                    [[0.88330609], [0.62367221], [0.75094243], [0.34889834]]\n",
    "                ),\n",
    "                \"b2\": np.array(\n",
    "                    [\n",
    "                        [0.26992789],\n",
    "                        [0.89588622],\n",
    "                        [0.42809119],\n",
    "                        [0.96484005],\n",
    "                        [0.6634415],\n",
    "                        [0.62169572],\n",
    "                        [0.11474597],\n",
    "                        [0.94948926],\n",
    "                        [0.44991213],\n",
    "                        [0.57838961],\n",
    "                    ]\n",
    "                ),\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"smaller_check\",\n",
    "            \"input\": {\"N\": 2, \"V\": 3, \"random_seed\": 1},\n",
    "            \"expected\": {\n",
    "                \"w1\": np.array(\n",
    "                    [\n",
    "                        [4.17022005e-01, 7.20324493e-01, 1.14374817e-04],\n",
    "                        [3.02332573e-01, 1.46755891e-01, 9.23385948e-02],\n",
    "                    ]\n",
    "                ),\n",
    "                \"w2\": np.array(\n",
    "                    [\n",
    "                        [0.18626021, 0.34556073],\n",
    "                        [0.39676747, 0.53881673],\n",
    "                        [0.41919451, 0.6852195],\n",
    "                    ]\n",
    "                ),\n",
    "                \"b1\": np.array([[0.20445225], [0.87811744]]),\n",
    "                \"b2\": np.array([[0.02738759], [0.67046751], [0.4173048]]),\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"small_check\",\n",
    "            \"input\": {\"N\": 3, \"V\": 5, \"random_seed\": 5},\n",
    "            \"expected\": {\n",
    "                \"w1\": np.array(\n",
    "                    [\n",
    "                        [0.22199317, 0.87073231, 0.20671916, 0.91861091, 0.48841119],\n",
    "                        [0.61174386, 0.76590786, 0.51841799, 0.2968005, 0.18772123],\n",
    "                        [0.08074127, 0.7384403, 0.44130922, 0.15830987, 0.87993703],\n",
    "                    ]\n",
    "                ),\n",
    "                \"w2\": np.array(\n",
    "                    [\n",
    "                        [0.27408646, 0.41423502, 0.29607993],\n",
    "                        [0.62878791, 0.57983781, 0.5999292],\n",
    "                        [0.26581912, 0.28468588, 0.25358821],\n",
    "                        [0.32756395, 0.1441643, 0.16561286],\n",
    "                        [0.96393053, 0.96022672, 0.18841466],\n",
    "                    ]\n",
    "                ),\n",
    "                \"b1\": np.array([[0.02430656], [0.20455555], [0.69984361]]),\n",
    "                \"b2\": np.array(\n",
    "                    [\n",
    "                        [0.77951459],\n",
    "                        [0.02293309],\n",
    "                        [0.57766286],\n",
    "                        [0.00164217],\n",
    "                        [0.51547261],\n",
    "                    ]\n",
    "                ),\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for test_case in test_cases:\n",
    "        tmp_W1, tmp_W2, tmp_b1, tmp_b2 = target(**test_case[\"input\"])        \n",
    "\n",
    "        try:\n",
    "            assert isinstance(tmp_W1, np.ndarray)\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": type(test_case[\"expected\"][\"w1\"]),\n",
    "                    \"got\": type(tmp_W1),\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong type for W1 matrix.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert isinstance(tmp_W2, np.ndarray)\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": type(test_case[\"expected\"][\"w2\"]),\n",
    "                    \"got\": type(tmp_W2),\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong type for W2 matrix.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert isinstance(tmp_b1, np.ndarray)\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": type(test_case[\"expected\"][\"b1\"]),\n",
    "                    \"got\": type(tmp_b1),\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong type for b1 vector.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert isinstance(tmp_b2, np.ndarray)\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": type(test_case[\"expected\"][\"b2\"]),\n",
    "                    \"got\": type(tmp_b2),\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong type for b2 vector.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        # Test initialization\n",
    "        try:\n",
    "            assert np.allclose(\n",
    "                tmp_W1, test_case[\"expected\"][\"w1\"], rtol=1e-05, atol=1e-08\n",
    "            )\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"w1\"],\n",
    "                    \"got\": tmp_W1,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong initialization for W1 matrix. Check the use of the random seed.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert np.allclose(\n",
    "                tmp_W2, test_case[\"expected\"][\"w2\"], rtol=1e-05, atol=1e-08\n",
    "            )\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"w2\"],\n",
    "                    \"got\": tmp_W2,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong initialization for W2 matrix. Check the use of the random seed.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert np.allclose(\n",
    "                tmp_b1, test_case[\"expected\"][\"b1\"], rtol=1e-05, atol=1e-08\n",
    "            )\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"b1\"],\n",
    "                    \"got\": tmp_b1,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong initialization for b1 vector. Check the use of the random seed.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert np.allclose(\n",
    "                tmp_b2, test_case[\"expected\"][\"b2\"], rtol=1e-05, atol=1e-08\n",
    "            )\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"b2\"],\n",
    "                    \"got\": tmp_b2,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong initialization for b2 vector. Check the use of the random seed.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        # Testing shapes\n",
    "        try:\n",
    "            assert tmp_W1.shape == test_case[\"expected\"][\"w1\"].shape\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"w1\"].shape,\n",
    "                    \"got\": tmp_W1.shape,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong shape for W1 matrix.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert tmp_W2.shape == test_case[\"expected\"][\"w2\"].shape\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"w2\"].shape,\n",
    "                    \"got\": tmp_W2.shape,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong shape for W2 matrix.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert tmp_b1.shape == test_case[\"expected\"][\"b1\"].shape\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"b1\"].shape,\n",
    "                    \"got\": tmp_b1.shape,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong shape for b1 vector.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert tmp_b2.shape == test_case[\"expected\"][\"b2\"].shape\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"b2\"].shape,\n",
    "                    \"got\": tmp_b2.shape,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong shape for b2 vector.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "    if len(failed_cases) == 0:\n",
    "        print(\"\\033[92m All tests passed\")\n",
    "    else:\n",
    "        print(\"\\033[92m\", successful_cases, \" Tests passed\")\n",
    "        print(\"\\033[91m\", len(failed_cases), \" Tests failed\")\n",
    "\n",
    "    # return failed_cases, len(failed_cases) + successful_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_softmax(target):\n",
    "    successful_cases = 0\n",
    "    failed_cases = []\n",
    "\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"name\": \"default_check\",\n",
    "            \"input\": np.array([[1, 2, 3], [1, 1, 1]]),\n",
    "            \"expected\": np.array(\n",
    "                [[0.5, 0.73105858, 0.88079708], [0.5, 0.26894142, 0.11920292]]\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"larger_check\",\n",
    "            \"input\": np.array(\n",
    "                [[1, 2, 3, 4], [1, 1, 1, 1], [-1, 0, 0, 3], [9, 8, 7, 6], [5, 4, 3, 2]]\n",
    "            ),\n",
    "            \"expected\": np.array(\n",
    "                [\n",
    "                    [3.29197356e-04, 2.42529448e-03, 1.76108202e-02, 1.11831081e-01],\n",
    "                    [3.29197356e-04, 8.92215977e-04, 2.38336534e-03, 5.56774167e-03],\n",
    "                    [4.45520174e-05, 3.28227915e-04, 8.76791109e-04, 4.11403556e-02],\n",
    "                    [9.81323487e-01, 9.78433625e-01, 9.61518203e-01, 8.26326131e-01],\n",
    "                    [1.79735666e-02, 1.79206369e-02, 1.76108202e-02, 1.51346910e-02],\n",
    "                ]\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for test_case in test_cases:\n",
    "        result = target(test_case[\"input\"])\n",
    "\n",
    "        try:\n",
    "            assert isinstance(result, np.ndarray)\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": type(test_case[\"expected\"]),\n",
    "                    \"got\": type(result),\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output type for softmax function.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert np.allclose(result, test_case[\"expected\"])\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"],\n",
    "                    \"got\": result,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output for softmax function.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert result.shape, test_case[\"expected\"].shape\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"].shape,\n",
    "                    \"got\": result.shape,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong shape for softmax function. Check the axis when you perform the sum in the denominator.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "    if len(failed_cases) == 0:\n",
    "        print(\"\\033[92m All tests passed\")\n",
    "    else:\n",
    "        print(\"\\033[92m\", successful_cases, \" Tests passed\")\n",
    "        print(\"\\033[91m\", len(failed_cases), \" Tests failed\")\n",
    "\n",
    "    # return failed_cases, len(failed_cases) + successful_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forward_prop(target):\n",
    "    successful_cases = 0\n",
    "    failed_cases = []\n",
    "\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"name\": \"default_check\",\n",
    "            \"input\": {\n",
    "                \"x\": np.array([[0, 1, 0]]).T,\n",
    "                \"W1\": np.array(\n",
    "                    [\n",
    "                        [4.17022005e-01, 7.20324493e-01, 1.14374817e-04],\n",
    "                        [3.02332573e-01, 1.46755891e-01, 9.23385948e-02],\n",
    "                    ]\n",
    "                ),\n",
    "                \"W2\": np.array(\n",
    "                    [\n",
    "                        [0.18626021, 0.34556073],\n",
    "                        [0.39676747, 0.53881673],\n",
    "                        [0.41919451, 0.6852195],\n",
    "                    ]\n",
    "                ),\n",
    "                \"b1\": np.array([[0.20445225], [0.87811744]]),\n",
    "                \"b2\": np.array([[0.02738759], [0.67046751], [0.4173048]]),\n",
    "            },\n",
    "            \"expected\": (\n",
    "                np.array([[0.55379268], [1.58960774], [1.50722933]]),\n",
    "                np.array([[0.92477674], [1.02487333]]),\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for test_case in test_cases:\n",
    "        result = target(**test_case[\"input\"])\n",
    "\n",
    "        try:\n",
    "            assert isinstance(result[0], np.ndarray)\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": type(test_case[\"expected\"][0]),\n",
    "                    \"got\": type(result[0]),\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong type for z vector.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert isinstance(result[1], np.ndarray)\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": type(test_case[\"expected\"][1]),\n",
    "                    \"got\": type(result[1]),\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong type for h vector.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        # Test values\n",
    "        try:\n",
    "            assert np.allclose(result[0], test_case[\"expected\"][0])\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][0],\n",
    "                    \"got\": result[0],\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output values for z vector.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert np.allclose(result[1], test_case[\"expected\"][1])\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][1],\n",
    "                    \"got\": result[1],\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong type for h vector.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        # Test shapes\n",
    "        try:\n",
    "            assert result[0].shape == test_case[\"expected\"][0].shape\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][0].shape,\n",
    "                    \"got\": result[0].shape,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output shape for z vector.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert result[1].shape == test_case[\"expected\"][1].shape\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][1].shape,\n",
    "                    \"got\": result[1].shape,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output shape for h vector.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "    if len(failed_cases) == 0:\n",
    "        print(\"\\033[92m All tests passed\")\n",
    "    else:\n",
    "        print(\"\\033[92m\", successful_cases, \" Tests passed\")\n",
    "        print(\"\\033[91m\", len(failed_cases), \" Tests failed\")\n",
    "\n",
    "    # return failed_cases, len(failed_cases) + successful_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_back_prop(target):\n",
    "    successful_cases = 0\n",
    "    failed_cases = []\n",
    "\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"name\": \"default_check\",\n",
    "            \"input\": {\n",
    "                \"x\": np.array(\n",
    "                    [\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                    ]\n",
    "                ),\n",
    "                \"yhat\": np.array(\n",
    "                    [\n",
    "                        [0.09488382, 0.09488382, 0.09488382, 0.09488382],\n",
    "                        [0.07354783, 0.07354783, 0.07354783, 0.07354783],\n",
    "                        [0.04061033, 0.04061033, 0.04061033, 0.04061033],\n",
    "                        [0.11081115, 0.11081115, 0.11081115, 0.11081115],\n",
    "                        [0.06029008, 0.06029008, 0.06029008, 0.06029008],\n",
    "                        [0.15000559, 0.15000559, 0.15000559, 0.15000559],\n",
    "                        [0.12740163, 0.12740163, 0.12740163, 0.12740163],\n",
    "                        [0.14957542, 0.14957542, 0.14957542, 0.14957542],\n",
    "                        [0.1007054, 0.1007054, 0.1007054, 0.1007054],\n",
    "                        [0.09216876, 0.09216876, 0.09216876, 0.09216876],\n",
    "                    ]\n",
    "                ),\n",
    "                \"y\": np.array(\n",
    "                    [\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [1.0, 1.0, 1.0, 1.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                    ]\n",
    "                ),\n",
    "                \"h\": np.array(\n",
    "                    [\n",
    "                        [0.8118587, 0.8118587, 0.8118587, 0.8118587],\n",
    "                        [0.87496164, 0.87496164, 0.87496164, 0.87496164],\n",
    "                        [0.68841325, 0.68841325, 0.68841325, 0.68841325],\n",
    "                        [0.56949441, 0.56949441, 0.56949441, 0.56949441],\n",
    "                        [0.16097144, 0.16097144, 0.16097144, 0.16097144],\n",
    "                        [0.46688002, 0.46688002, 0.46688002, 0.46688002],\n",
    "                        [0.34517205, 0.34517205, 0.34517205, 0.34517205],\n",
    "                        [0.22503996, 0.22503996, 0.22503996, 0.22503996],\n",
    "                        [0.59251187, 0.59251187, 0.59251187, 0.59251187],\n",
    "                        [0.31226984, 0.31226984, 0.31226984, 0.31226984],\n",
    "                        [0.91630555, 0.91630555, 0.91630555, 0.91630555],\n",
    "                        [0.90963552, 0.90963552, 0.90963552, 0.90963552],\n",
    "                        [0.25711829, 0.25711829, 0.25711829, 0.25711829],\n",
    "                        [0.1108913, 0.1108913, 0.1108913, 0.1108913],\n",
    "                        [0.19296273, 0.19296273, 0.19296273, 0.19296273],\n",
    "                    ]\n",
    "                ),\n",
    "                \"W1\": np.array(\n",
    "                    [\n",
    "                        [\n",
    "                            4.17022005e-01,\n",
    "                            7.20324493e-01,\n",
    "                            1.14374817e-04,\n",
    "                            3.02332573e-01,\n",
    "                            1.46755891e-01,\n",
    "                            9.23385948e-02,\n",
    "                            1.86260211e-01,\n",
    "                            3.45560727e-01,\n",
    "                            3.96767474e-01,\n",
    "                            5.38816734e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            4.19194514e-01,\n",
    "                            6.85219500e-01,\n",
    "                            2.04452250e-01,\n",
    "                            8.78117436e-01,\n",
    "                            2.73875932e-02,\n",
    "                            6.70467510e-01,\n",
    "                            4.17304802e-01,\n",
    "                            5.58689828e-01,\n",
    "                            1.40386939e-01,\n",
    "                            1.98101489e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            8.00744569e-01,\n",
    "                            9.68261576e-01,\n",
    "                            3.13424178e-01,\n",
    "                            6.92322616e-01,\n",
    "                            8.76389152e-01,\n",
    "                            8.94606664e-01,\n",
    "                            8.50442114e-02,\n",
    "                            3.90547832e-02,\n",
    "                            1.69830420e-01,\n",
    "                            8.78142503e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            9.83468338e-02,\n",
    "                            4.21107625e-01,\n",
    "                            9.57889530e-01,\n",
    "                            5.33165285e-01,\n",
    "                            6.91877114e-01,\n",
    "                            3.15515631e-01,\n",
    "                            6.86500928e-01,\n",
    "                            8.34625672e-01,\n",
    "                            1.82882773e-02,\n",
    "                            7.50144315e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            9.88861089e-01,\n",
    "                            7.48165654e-01,\n",
    "                            2.80443992e-01,\n",
    "                            7.89279328e-01,\n",
    "                            1.03226007e-01,\n",
    "                            4.47893526e-01,\n",
    "                            9.08595503e-01,\n",
    "                            2.93614148e-01,\n",
    "                            2.87775339e-01,\n",
    "                            1.30028572e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            1.93669579e-02,\n",
    "                            6.78835533e-01,\n",
    "                            2.11628116e-01,\n",
    "                            2.65546659e-01,\n",
    "                            4.91573159e-01,\n",
    "                            5.33625451e-02,\n",
    "                            5.74117605e-01,\n",
    "                            1.46728575e-01,\n",
    "                            5.89305537e-01,\n",
    "                            6.99758360e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            1.02334429e-01,\n",
    "                            4.14055988e-01,\n",
    "                            6.94400158e-01,\n",
    "                            4.14179270e-01,\n",
    "                            4.99534589e-02,\n",
    "                            5.35896406e-01,\n",
    "                            6.63794645e-01,\n",
    "                            5.14889112e-01,\n",
    "                            9.44594756e-01,\n",
    "                            5.86555041e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            9.03401915e-01,\n",
    "                            1.37474704e-01,\n",
    "                            1.39276347e-01,\n",
    "                            8.07391289e-01,\n",
    "                            3.97676837e-01,\n",
    "                            1.65354197e-01,\n",
    "                            9.27508580e-01,\n",
    "                            3.47765860e-01,\n",
    "                            7.50812103e-01,\n",
    "                            7.25997985e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            8.83306091e-01,\n",
    "                            6.23672207e-01,\n",
    "                            7.50942434e-01,\n",
    "                            3.48898342e-01,\n",
    "                            2.69927892e-01,\n",
    "                            8.95886218e-01,\n",
    "                            4.28091190e-01,\n",
    "                            9.64840047e-01,\n",
    "                            6.63441498e-01,\n",
    "                            6.21695720e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            1.14745973e-01,\n",
    "                            9.49489259e-01,\n",
    "                            4.49912133e-01,\n",
    "                            5.78389614e-01,\n",
    "                            4.08136803e-01,\n",
    "                            2.37026980e-01,\n",
    "                            9.03379521e-01,\n",
    "                            5.73679487e-01,\n",
    "                            2.87032703e-03,\n",
    "                            6.17144914e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            3.26644902e-01,\n",
    "                            5.27058102e-01,\n",
    "                            8.85942099e-01,\n",
    "                            3.57269760e-01,\n",
    "                            9.08535151e-01,\n",
    "                            6.23360116e-01,\n",
    "                            1.58212428e-02,\n",
    "                            9.29437234e-01,\n",
    "                            6.90896918e-01,\n",
    "                            9.97322850e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            1.72340508e-01,\n",
    "                            1.37135750e-01,\n",
    "                            9.32595463e-01,\n",
    "                            6.96818161e-01,\n",
    "                            6.60001727e-02,\n",
    "                            7.55463053e-01,\n",
    "                            7.53876188e-01,\n",
    "                            9.23024536e-01,\n",
    "                            7.11524759e-01,\n",
    "                            1.24270962e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            1.98801338e-02,\n",
    "                            2.62109869e-02,\n",
    "                            2.83064880e-02,\n",
    "                            2.46211068e-01,\n",
    "                            8.60027949e-01,\n",
    "                            5.38831064e-01,\n",
    "                            5.52821979e-01,\n",
    "                            8.42030892e-01,\n",
    "                            1.24173315e-01,\n",
    "                            2.79183679e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            5.85759271e-01,\n",
    "                            9.69595748e-01,\n",
    "                            5.61030219e-01,\n",
    "                            1.86472894e-02,\n",
    "                            8.00632673e-01,\n",
    "                            2.32974274e-01,\n",
    "                            8.07105196e-01,\n",
    "                            3.87860644e-01,\n",
    "                            8.63541855e-01,\n",
    "                            7.47121643e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            5.56240234e-01,\n",
    "                            1.36455226e-01,\n",
    "                            5.99176895e-02,\n",
    "                            1.21343456e-01,\n",
    "                            4.45518785e-02,\n",
    "                            1.07494129e-01,\n",
    "                            2.25709339e-01,\n",
    "                            7.12988980e-01,\n",
    "                            5.59716982e-01,\n",
    "                            1.25559802e-02,\n",
    "                        ],\n",
    "                    ]\n",
    "                ),\n",
    "                \"W2\": np.array(\n",
    "                    [\n",
    "                        [\n",
    "                            7.19742797e-02,\n",
    "                            9.67276330e-01,\n",
    "                            5.68100462e-01,\n",
    "                            2.03293235e-01,\n",
    "                            2.52325745e-01,\n",
    "                            7.43825854e-01,\n",
    "                            1.95429481e-01,\n",
    "                            5.81358927e-01,\n",
    "                            9.70019989e-01,\n",
    "                            8.46828801e-01,\n",
    "                            2.39847759e-01,\n",
    "                            4.93769714e-01,\n",
    "                            6.19955718e-01,\n",
    "                            8.28980900e-01,\n",
    "                            1.56791395e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            1.85762022e-02,\n",
    "                            7.00221437e-02,\n",
    "                            4.86345111e-01,\n",
    "                            6.06329462e-01,\n",
    "                            5.68851437e-01,\n",
    "                            3.17362409e-01,\n",
    "                            9.88616154e-01,\n",
    "                            5.79745219e-01,\n",
    "                            3.80141173e-01,\n",
    "                            5.50948219e-01,\n",
    "                            7.45334431e-01,\n",
    "                            6.69232893e-01,\n",
    "                            2.64919558e-01,\n",
    "                            6.63348344e-02,\n",
    "                            3.70084198e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            6.29717507e-01,\n",
    "                            2.10174010e-01,\n",
    "                            7.52755554e-01,\n",
    "                            6.65364814e-02,\n",
    "                            2.60315099e-01,\n",
    "                            8.04754564e-01,\n",
    "                            1.93434283e-01,\n",
    "                            6.39460881e-01,\n",
    "                            5.24670309e-01,\n",
    "                            9.24807970e-01,\n",
    "                            2.63296770e-01,\n",
    "                            6.59610907e-02,\n",
    "                            7.35065963e-01,\n",
    "                            7.72178030e-01,\n",
    "                            9.07815853e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            9.31972069e-01,\n",
    "                            1.39515730e-02,\n",
    "                            2.34362086e-01,\n",
    "                            6.16778357e-01,\n",
    "                            9.49016321e-01,\n",
    "                            9.50176119e-01,\n",
    "                            5.56653188e-01,\n",
    "                            9.15606350e-01,\n",
    "                            6.41566209e-01,\n",
    "                            3.90007714e-01,\n",
    "                            4.85990667e-01,\n",
    "                            6.04310483e-01,\n",
    "                            5.49547922e-01,\n",
    "                            9.26181427e-01,\n",
    "                            9.18733436e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            3.94875613e-01,\n",
    "                            9.63262528e-01,\n",
    "                            1.73955667e-01,\n",
    "                            1.26329519e-01,\n",
    "                            1.35079158e-01,\n",
    "                            5.05662166e-01,\n",
    "                            2.15248053e-02,\n",
    "                            9.47970211e-01,\n",
    "                            8.27115471e-01,\n",
    "                            1.50189807e-02,\n",
    "                            1.76196256e-01,\n",
    "                            3.32063574e-01,\n",
    "                            1.30996845e-01,\n",
    "                            8.09490692e-01,\n",
    "                            3.44736653e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            9.40107482e-01,\n",
    "                            5.82014180e-01,\n",
    "                            8.78831984e-01,\n",
    "                            8.44734445e-01,\n",
    "                            9.05392319e-01,\n",
    "                            4.59880266e-01,\n",
    "                            5.46346816e-01,\n",
    "                            7.98603591e-01,\n",
    "                            2.85718852e-01,\n",
    "                            4.90253523e-01,\n",
    "                            5.99110308e-01,\n",
    "                            1.55332756e-02,\n",
    "                            5.93481408e-01,\n",
    "                            4.33676349e-01,\n",
    "                            8.07360529e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            3.15244803e-01,\n",
    "                            8.92888709e-01,\n",
    "                            5.77857215e-01,\n",
    "                            1.84010202e-01,\n",
    "                            7.87929234e-01,\n",
    "                            6.12031177e-01,\n",
    "                            5.39092721e-02,\n",
    "                            4.20193680e-01,\n",
    "                            6.79068837e-01,\n",
    "                            9.18601778e-01,\n",
    "                            4.02024891e-04,\n",
    "                            9.76759149e-01,\n",
    "                            3.76580315e-01,\n",
    "                            9.73783538e-01,\n",
    "                            6.04716101e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            8.28845808e-01,\n",
    "                            5.74711505e-01,\n",
    "                            6.28076198e-01,\n",
    "                            2.85576282e-01,\n",
    "                            5.86833341e-01,\n",
    "                            7.50021764e-01,\n",
    "                            8.58313836e-01,\n",
    "                            7.55082188e-01,\n",
    "                            6.98057248e-01,\n",
    "                            8.64479430e-01,\n",
    "                            3.22680997e-01,\n",
    "                            6.70788791e-01,\n",
    "                            4.50873936e-01,\n",
    "                            3.82102752e-01,\n",
    "                            4.10811350e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            4.01479583e-01,\n",
    "                            3.17383946e-01,\n",
    "                            6.21919368e-01,\n",
    "                            4.30247271e-01,\n",
    "                            9.73802078e-01,\n",
    "                            6.77800891e-01,\n",
    "                            1.98569888e-01,\n",
    "                            4.26701009e-01,\n",
    "                            3.43346240e-01,\n",
    "                            7.97638804e-01,\n",
    "                            8.79998289e-01,\n",
    "                            9.03841956e-01,\n",
    "                            6.62719812e-01,\n",
    "                            2.70208262e-01,\n",
    "                            2.52366702e-01,\n",
    "                        ],\n",
    "                        [\n",
    "                            8.54897943e-01,\n",
    "                            5.27714646e-01,\n",
    "                            8.02161084e-01,\n",
    "                            5.72488517e-01,\n",
    "                            7.33142525e-01,\n",
    "                            5.19011627e-01,\n",
    "                            7.70883911e-01,\n",
    "                            5.68857991e-01,\n",
    "                            4.65709879e-01,\n",
    "                            3.42688908e-01,\n",
    "                            6.82093484e-02,\n",
    "                            3.77924179e-01,\n",
    "                            7.96260777e-02,\n",
    "                            9.82817114e-01,\n",
    "                            1.81612851e-01,\n",
    "                        ],\n",
    "                    ]\n",
    "                ),\n",
    "                \"b1\": np.array(\n",
    "                    [\n",
    "                        [0.8118587],\n",
    "                        [0.87496164],\n",
    "                        [0.68841325],\n",
    "                        [0.56949441],\n",
    "                        [0.16097144],\n",
    "                        [0.46688002],\n",
    "                        [0.34517205],\n",
    "                        [0.22503996],\n",
    "                        [0.59251187],\n",
    "                        [0.31226984],\n",
    "                        [0.91630555],\n",
    "                        [0.90963552],\n",
    "                        [0.25711829],\n",
    "                        [0.1108913],\n",
    "                        [0.19296273],\n",
    "                    ]\n",
    "                ),\n",
    "                \"b2\": np.array(\n",
    "                    [\n",
    "                        [0.49958417],\n",
    "                        [0.72858567],\n",
    "                        [0.20819444],\n",
    "                        [0.24803356],\n",
    "                        [0.85167187],\n",
    "                        [0.41584872],\n",
    "                        [0.61668507],\n",
    "                        [0.23366614],\n",
    "                        [0.10196726],\n",
    "                        [0.51585702],\n",
    "                    ]\n",
    "                ),\n",
    "                \"batch_size\": 4,\n",
    "            },\n",
    "            \"expected\": {\n",
    "                \"grad_W1\": np.array(\n",
    "                    [\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    ]\n",
    "                ),\n",
    "                \"grad_W2\": np.array(\n",
    "                    [\n",
    "                        [\n",
    "                            0.07703226,\n",
    "                            0.0830197,\n",
    "                            0.06531928,\n",
    "                            0.05403581,\n",
    "                            0.01527358,\n",
    "                            0.04429936,\n",
    "                            0.03275124,\n",
    "                            0.02135265,\n",
    "                            0.05621979,\n",
    "                            0.02962936,\n",
    "                            0.08694257,\n",
    "                            0.08630969,\n",
    "                            0.02439637,\n",
    "                            0.01052179,\n",
    "                            0.01830904,\n",
    "                        ],\n",
    "                        [\n",
    "                            -0.75214825,\n",
    "                            -0.81061012,\n",
    "                            -0.63778195,\n",
    "                            -0.52760933,\n",
    "                            -0.14913234,\n",
    "                            -0.43254201,\n",
    "                            -0.3197854,\n",
    "                            -0.20848876,\n",
    "                            -0.54893391,\n",
    "                            -0.28930307,\n",
    "                            -0.84891327,\n",
    "                            -0.84273381,\n",
    "                            -0.2382078,\n",
    "                            -0.10273549,\n",
    "                            -0.17877074,\n",
    "                        ],\n",
    "                        [\n",
    "                            0.03296985,\n",
    "                            0.03553248,\n",
    "                            0.02795669,\n",
    "                            0.02312735,\n",
    "                            0.0065371,\n",
    "                            0.01896015,\n",
    "                            0.01401755,\n",
    "                            0.00913895,\n",
    "                            0.0240621,\n",
    "                            0.01268138,\n",
    "                            0.03721147,\n",
    "                            0.03694059,\n",
    "                            0.01044166,\n",
    "                            0.00450333,\n",
    "                            0.00783628,\n",
    "                        ],\n",
    "                        [\n",
    "                            0.08996299,\n",
    "                            0.0969555,\n",
    "                            0.07628386,\n",
    "                            0.06310633,\n",
    "                            0.01783743,\n",
    "                            0.05173551,\n",
    "                            0.03824891,\n",
    "                            0.02493694,\n",
    "                            0.06565692,\n",
    "                            0.03460298,\n",
    "                            0.10153687,\n",
    "                            0.10079776,\n",
    "                            0.02849157,\n",
    "                            0.01228799,\n",
    "                            0.02138242,\n",
    "                        ],\n",
    "                        [\n",
    "                            0.04894702,\n",
    "                            0.0527515,\n",
    "                            0.04150449,\n",
    "                            0.03433486,\n",
    "                            0.00970498,\n",
    "                            0.02814823,\n",
    "                            0.02081045,\n",
    "                            0.01356768,\n",
    "                            0.03572259,\n",
    "                            0.01882677,\n",
    "                            0.05524413,\n",
    "                            0.054842,\n",
    "                            0.01550168,\n",
    "                            0.00668564,\n",
    "                            0.01163374,\n",
    "                        ],\n",
    "                        [\n",
    "                            0.12178334,\n",
    "                            0.13124914,\n",
    "                            0.10326583,\n",
    "                            0.08542734,\n",
    "                            0.02414662,\n",
    "                            0.07003461,\n",
    "                            0.05177774,\n",
    "                            0.03375725,\n",
    "                            0.08888009,\n",
    "                            0.04684222,\n",
    "                            0.13745095,\n",
    "                            0.13645041,\n",
    "                            0.03856918,\n",
    "                            0.01663431,\n",
    "                            0.02894549,\n",
    "                        ],\n",
    "                        [\n",
    "                            0.10343212,\n",
    "                            0.11147154,\n",
    "                            0.08770497,\n",
    "                            0.07255452,\n",
    "                            0.02050802,\n",
    "                            0.05948128,\n",
    "                            0.04397548,\n",
    "                            0.02867046,\n",
    "                            0.07548698,\n",
    "                            0.03978369,\n",
    "                            0.11673882,\n",
    "                            0.11588905,\n",
    "                            0.03275729,\n",
    "                            0.01412773,\n",
    "                            0.02458377,\n",
    "                        ],\n",
    "                        [\n",
    "                            0.12143411,\n",
    "                            0.13087276,\n",
    "                            0.1029697,\n",
    "                            0.08518237,\n",
    "                            0.02407737,\n",
    "                            0.06983378,\n",
    "                            0.05162926,\n",
    "                            0.03366045,\n",
    "                            0.08862521,\n",
    "                            0.04670789,\n",
    "                            0.13705679,\n",
    "                            0.13605912,\n",
    "                            0.03845858,\n",
    "                            0.01658661,\n",
    "                            0.02886248,\n",
    "                        ],\n",
    "                        [\n",
    "                            0.08175855,\n",
    "                            0.08811336,\n",
    "                            0.06932693,\n",
    "                            0.05735116,\n",
    "                            0.01621069,\n",
    "                            0.04701734,\n",
    "                            0.03476069,\n",
    "                            0.02266274,\n",
    "                            0.05966914,\n",
    "                            0.03144726,\n",
    "                            0.09227692,\n",
    "                            0.09160521,\n",
    "                            0.0258932,\n",
    "                            0.01116735,\n",
    "                            0.01943239,\n",
    "                        ],\n",
    "                        [\n",
    "                            0.07482801,\n",
    "                            0.08064413,\n",
    "                            0.06345019,\n",
    "                            0.05248959,\n",
    "                            0.01483654,\n",
    "                            0.04303175,\n",
    "                            0.03181408,\n",
    "                            0.02074165,\n",
    "                            0.05461108,\n",
    "                            0.02878152,\n",
    "                            0.08445474,\n",
    "                            0.08383998,\n",
    "                            0.02369827,\n",
    "                            0.01022071,\n",
    "                            0.01778514,\n",
    "                        ],\n",
    "                    ]\n",
    "                ),\n",
    "                \"grad_b1\": np.array(\n",
    "                    [\n",
    "                        [0.56665732],\n",
    "                        [0.46268776],\n",
    "                        [0.10631469],\n",
    "                        [0.0],\n",
    "                        [0.11041817],\n",
    "                        [0.32025188],\n",
    "                        [0.0],\n",
    "                        [0.08430877],\n",
    "                        [0.19341],\n",
    "                        [0.08339139],\n",
    "                        [0.0],\n",
    "                        [0.0],\n",
    "                        [0.19055422],\n",
    "                        [0.56405984],\n",
    "                        [0.13321987],\n",
    "                    ]\n",
    "                ),\n",
    "                \"grad_b2\": np.array(\n",
    "                    [\n",
    "                        [0.09488382],\n",
    "                        [-0.92645217],\n",
    "                        [0.04061033],\n",
    "                        [0.11081115],\n",
    "                        [0.06029008],\n",
    "                        [0.15000559],\n",
    "                        [0.12740163],\n",
    "                        [0.14957542],\n",
    "                        [0.1007054],\n",
    "                        [0.09216876],\n",
    "                    ]\n",
    "                ),\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"default_check\",\n",
    "            \"input\": {\n",
    "                \"x\": np.array(\n",
    "                    [\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                    ]\n",
    "                ),\n",
    "                \"yhat\": np.array(\n",
    "                    [\n",
    "                        [0.22636192, 0.22636192, 0.22636192, 0.22636192],\n",
    "                        [0.40947153, 0.40947153, 0.40947153, 0.40947153],\n",
    "                        [0.12268763, 0.12268763, 0.12268763, 0.12268763],\n",
    "                        [0.06530444, 0.06530444, 0.06530444, 0.06530444],\n",
    "                        [0.17617448, 0.17617448, 0.17617448, 0.17617448],\n",
    "                    ]\n",
    "                ),\n",
    "                \"y\": np.array(\n",
    "                    [\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [1.0, 1.0, 1.0, 1.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0],\n",
    "                    ]\n",
    "                ),\n",
    "                \"h\": np.array(\n",
    "                    [\n",
    "                        [0.9851368, 0.9851368, 0.9851368, 0.9851368],\n",
    "                        [0.80140153, 0.80140153, 0.80140153, 0.80140153],\n",
    "                        [0.0539621, 0.0539621, 0.0539621, 0.0539621],\n",
    "                        [0.19047777, 0.19047777, 0.19047777, 0.19047777],\n",
    "                        [0.45241885, 0.45241885, 0.45241885, 0.45241885],\n",
    "                        [0.70294208, 0.70294208, 0.70294208, 0.70294208],\n",
    "                        [0.33204815, 0.33204815, 0.33204815, 0.33204815],\n",
    "                        [0.3599832, 0.3599832, 0.3599832, 0.3599832],\n",
    "                        [0.92147057, 0.92147057, 0.92147057, 0.92147057],\n",
    "                        [0.95363051, 0.95363051, 0.95363051, 0.95363051],\n",
    "                    ]\n",
    "                ),\n",
    "                \"W1\": np.array(\n",
    "                    [\n",
    "                        [0.22199317, 0.87073231, 0.20671916, 0.91861091, 0.48841119],\n",
    "                        [0.61174386, 0.76590786, 0.51841799, 0.2968005, 0.18772123],\n",
    "                        [0.08074127, 0.7384403, 0.44130922, 0.15830987, 0.87993703],\n",
    "                        [0.27408646, 0.41423502, 0.29607993, 0.62878791, 0.57983781],\n",
    "                        [0.5999292, 0.26581912, 0.28468588, 0.25358821, 0.32756395],\n",
    "                        [0.1441643, 0.16561286, 0.96393053, 0.96022672, 0.18841466],\n",
    "                        [0.02430656, 0.20455555, 0.69984361, 0.77951459, 0.02293309],\n",
    "                        [0.57766286, 0.00164217, 0.51547261, 0.63979518, 0.9856244],\n",
    "                        [0.2590976, 0.80249689, 0.87048309, 0.92274961, 0.00221421],\n",
    "                        [0.46948837, 0.98146874, 0.3989448, 0.81373248, 0.5464565],\n",
    "                    ]\n",
    "                ),\n",
    "                \"W2\": np.array(\n",
    "                    [\n",
    "                        [\n",
    "                            0.77085409,\n",
    "                            0.48493107,\n",
    "                            0.02911156,\n",
    "                            0.08652569,\n",
    "                            0.11145381,\n",
    "                            0.25124511,\n",
    "                            0.96491529,\n",
    "                            0.63176605,\n",
    "                            0.8166602,\n",
    "                            0.566082,\n",
    "                        ],\n",
    "                        [\n",
    "                            0.63535621,\n",
    "                            0.81190239,\n",
    "                            0.92668262,\n",
    "                            0.91262676,\n",
    "                            0.82481072,\n",
    "                            0.09420273,\n",
    "                            0.36104842,\n",
    "                            0.03550903,\n",
    "                            0.54635835,\n",
    "                            0.79614272,\n",
    "                        ],\n",
    "                        [\n",
    "                            0.0511428,\n",
    "                            0.18866774,\n",
    "                            0.36547777,\n",
    "                            0.24429087,\n",
    "                            0.79508747,\n",
    "                            0.35209494,\n",
    "                            0.63887768,\n",
    "                            0.49341505,\n",
    "                            0.58349974,\n",
    "                            0.93929935,\n",
    "                        ],\n",
    "                        [\n",
    "                            0.94354008,\n",
    "                            0.11169243,\n",
    "                            0.84355497,\n",
    "                            0.34602815,\n",
    "                            0.10082727,\n",
    "                            0.38340907,\n",
    "                            0.5103548,\n",
    "                            0.96110308,\n",
    "                            0.37151262,\n",
    "                            0.01236941,\n",
    "                        ],\n",
    "                        [\n",
    "                            0.85970689,\n",
    "                            0.11111075,\n",
    "                            0.47833904,\n",
    "                            0.84998003,\n",
    "                            0.51473797,\n",
    "                            0.44660783,\n",
    "                            0.80047642,\n",
    "                            0.02039138,\n",
    "                            0.57261865,\n",
    "                            0.41138362,\n",
    "                        ],\n",
    "                    ]\n",
    "                ),\n",
    "                \"b1\": np.array(\n",
    "                    [\n",
    "                        [0.9851368],\n",
    "                        [0.80140153],\n",
    "                        [0.0539621],\n",
    "                        [0.19047777],\n",
    "                        [0.45241885],\n",
    "                        [0.70294208],\n",
    "                        [0.33204815],\n",
    "                        [0.3599832],\n",
    "                        [0.92147057],\n",
    "                        [0.95363051],\n",
    "                    ]\n",
    "                ),\n",
    "                \"b2\": np.array(\n",
    "                    [\n",
    "                        [0.40768573],\n",
    "                        [0.89857115],\n",
    "                        [0.33025325],\n",
    "                        [0.08273857],\n",
    "                        [0.52671757],\n",
    "                    ]\n",
    "                ),\n",
    "                \"batch_size\": 4,\n",
    "            },\n",
    "            \"expected\": {\n",
    "                \"grad_W1\": np.array(\n",
    "                    [\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    ]\n",
    "                ),\n",
    "                \"grad_W2\": np.array(\n",
    "                    [\n",
    "                        [\n",
    "                            0.44599491,\n",
    "                            0.36281358,\n",
    "                            0.02442993,\n",
    "                            0.08623383,\n",
    "                            0.2048208,\n",
    "                            0.31823863,\n",
    "                            0.15032611,\n",
    "                            0.16297297,\n",
    "                            0.41717169,\n",
    "                            0.43173126,\n",
    "                        ],\n",
    "                        [\n",
    "                            -1.16350265,\n",
    "                            -0.94650084,\n",
    "                            -0.06373232,\n",
    "                            -0.2249651,\n",
    "                            -0.53433242,\n",
    "                            -0.83021462,\n",
    "                            -0.39216777,\n",
    "                            -0.42516065,\n",
    "                            -1.0883092,\n",
    "                            -1.12629192,\n",
    "                        ],\n",
    "                        [\n",
    "                            0.2417282,\n",
    "                            0.19664411,\n",
    "                            0.01324097,\n",
    "                            0.04673853,\n",
    "                            0.11101239,\n",
    "                            0.1724846,\n",
    "                            0.0814764,\n",
    "                            0.08833097,\n",
    "                            0.22610608,\n",
    "                            0.23399734,\n",
    "                        ],\n",
    "                        [\n",
    "                            0.12866761,\n",
    "                            0.10467015,\n",
    "                            0.00704793,\n",
    "                            0.02487809,\n",
    "                            0.05908992,\n",
    "                            0.09181047,\n",
    "                            0.04336843,\n",
    "                            0.047017,\n",
    "                            0.12035223,\n",
    "                            0.12455261,\n",
    "                        ],\n",
    "                        [\n",
    "                            0.34711193,\n",
    "                            0.282373,\n",
    "                            0.01901349,\n",
    "                            0.06711465,\n",
    "                            0.15940931,\n",
    "                            0.24768091,\n",
    "                            0.11699682,\n",
    "                            0.12683971,\n",
    "                            0.3246792,\n",
    "                            0.33601072,\n",
    "                        ],\n",
    "                    ]\n",
    "                ),\n",
    "                \"grad_b1\": np.array(\n",
    "                    [\n",
    "                        [0.03729288],\n",
    "                        [0.0],\n",
    "                        [0.0],\n",
    "                        [0.0],\n",
    "                        [0.0],\n",
    "                        [0.29631968],\n",
    "                        [0.5158901],\n",
    "                        [0.49786268],\n",
    "                        [0.11790206],\n",
    "                        [0.0],\n",
    "                    ]\n",
    "                ),\n",
    "                \"grad_b2\": np.array(\n",
    "                    [\n",
    "                        [0.45272384],\n",
    "                        [-1.18105694],\n",
    "                        [0.24537526],\n",
    "                        [0.13060887],\n",
    "                        [0.35234896],\n",
    "                    ]\n",
    "                ),\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    ###############\n",
    "    print(W2)\n",
    "\n",
    "    for test_case in test_cases:\n",
    "        tmp_grad_W1, tmp_grad_W2, tmp_grad_b1, tmp_grad_b2 = target(\n",
    "            **test_case[\"input\"]\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            assert tmp_grad_W1.shape == test_case[\"expected\"][\"grad_W1\"].shape\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"grad_W1\"].shape,\n",
    "                    \"got\": tmp_grad_W1.shape,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output shape for gradient of W1 matrix.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert tmp_grad_W2.shape == test_case[\"expected\"][\"grad_W2\"].shape\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"grad_W2\"].shape,\n",
    "                    \"got\": tmp_grad_W2.shape,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output shape for gradient of W2 matrix.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert tmp_grad_b1.shape == test_case[\"expected\"][\"grad_b1\"].shape\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"grad_b1\"].shape,\n",
    "                    \"got\": tmp_grad_b1.shape,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output shape for gradient of b1 vector.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert tmp_grad_b2.shape == test_case[\"expected\"][\"grad_b2\"].shape\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"grad_b2\"].shape,\n",
    "                    \"got\": tmp_grad_b2.shape,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output shape for gradient of b2 vector.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        # Testing values\n",
    "        try:\n",
    "            assert np.allclose(tmp_grad_W1, test_case[\"expected\"][\"grad_W1\"])\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"grad_W1\"],\n",
    "                    \"got\": tmp_grad_W1,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output values for gradient of W1 matrix.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert np.allclose(tmp_grad_W2, test_case[\"expected\"][\"grad_W2\"])\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"grad_W2\"],\n",
    "                    \"got\": tmp_grad_W2,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output values for gradient of W2 matrix.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert np.allclose(tmp_grad_b1, test_case[\"expected\"][\"grad_b1\"])\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"grad_b1\"],\n",
    "                    \"got\": tmp_grad_b1,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output values for gradient of b1 vector.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert np.allclose(tmp_grad_b2, test_case[\"expected\"][\"grad_b2\"])\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"grad_b2\"],\n",
    "                    \"got\": tmp_grad_b2,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output values for gradient of b2 vector.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "    if len(failed_cases) == 0:\n",
    "        print(\"\\033[92m All tests passed\")\n",
    "    else:\n",
    "        print(\"\\033[92m\", successful_cases, \" Tests passed\")\n",
    "        print(\"\\033[91m\", len(failed_cases), \" Tests failed\")\n",
    "\n",
    "    # return failed_cases, len(failed_cases) + successful_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def test_gradient_descent(target, data, word2Ind, N, V, num_iters):\n",
    "    successful_cases = 0\n",
    "    failed_cases = []\n",
    "\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"name\": \"default_check\",\n",
    "            \"input\": {\n",
    "                \"data\": data,\n",
    "                \"word2Ind\": word2Ind,\n",
    "                \"N\": N,\n",
    "                \"V\": V,\n",
    "                \"num_iters\": num_iters,\n",
    "                \"alpha\": 0.03,\n",
    "                \"random_seed\": 282,\n",
    "            },\n",
    "            \"expected\": {\n",
    "                \"W1\": pickle.load(\n",
    "                    open(\"./support_files/gradient_descent/w1.pkl\", \"rb\")\n",
    "                ),\n",
    "                \"W2\": pickle.load(\n",
    "                    open(\"./support_files/gradient_descent/w2.pkl\", \"rb\")\n",
    "                ),\n",
    "                \"b1\": pickle.load(\n",
    "                    open(\"./support_files/gradient_descent/b1.pkl\", \"rb\")\n",
    "                ),\n",
    "                \"b2\": pickle.load(\n",
    "                    open(\"./support_files/gradient_descent/b2.pkl\", \"rb\")\n",
    "                ),\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"small_check\",\n",
    "            \"input\": {\n",
    "                \"data\": data,\n",
    "                \"word2Ind\": word2Ind,\n",
    "                \"N\": 5,\n",
    "                \"V\": V,\n",
    "                \"num_iters\": num_iters,\n",
    "                \"alpha\": 0.01,\n",
    "                \"random_seed\": 5,\n",
    "            },\n",
    "            \"expected\": {\n",
    "                \"W1\": pickle.load(\n",
    "                    open(\"./support_files/gradient_descent/w1_exm2.pkl\", \"rb\")\n",
    "                ),\n",
    "                \"W2\": pickle.load(\n",
    "                    open(\"./support_files/gradient_descent/w2_exm2.pkl\", \"rb\")\n",
    "                ),\n",
    "                \"b1\": pickle.load(\n",
    "                    open(\"./support_files/gradient_descent/b1_exm2.pkl\", \"rb\")\n",
    "                ),\n",
    "                \"b2\": pickle.load(\n",
    "                    open(\"./support_files/gradient_descent/b2_exm2.pkl\", \"rb\")\n",
    "                ),\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for test_case in test_cases:\n",
    "        print(\"name\", test_case[\"name\"])\n",
    "        W1, W2, b1, b2 = target(**test_case[\"input\"])\n",
    "\n",
    "        try:\n",
    "            assert W1.shape == test_case[\"expected\"][\"W1\"].shape\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"W1\"].shape,\n",
    "                    \"got\": W1.shape,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output shape for W1 matrix.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert W2.shape == test_case[\"expected\"][\"W2\"].shape\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"W2\"].shape,\n",
    "                    \"got\": W2.shape,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output shape for W2 matrix.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert b1.shape == test_case[\"expected\"][\"b1\"].shape\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"b1\"].shape,\n",
    "                    \"got\": b1.shape,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output shape for b1 vector.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert b2.shape == test_case[\"expected\"][\"b2\"].shape\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"b2\"].shape,\n",
    "                    \"got\": b2.shape,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output shape for b2 vector.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        # Testing values\n",
    "        try:\n",
    "            assert np.allclose(W1, test_case[\"expected\"][\"W1\"])\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"W1\"],\n",
    "                    \"got\": W1,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output values for W1 matrix.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert np.allclose(W2, test_case[\"expected\"][\"W2\"])\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"W2\"],\n",
    "                    \"got\": W2,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output values for W2 matrix.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert np.allclose(b1, test_case[\"expected\"][\"b1\"])\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"b1\"],\n",
    "                    \"got\": b1,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output values for b1 vector.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            assert np.allclose(b2, test_case[\"expected\"][\"b2\"])\n",
    "            successful_cases += 1\n",
    "        except:\n",
    "            failed_cases.append(\n",
    "                {\n",
    "                    \"name\": test_case[\"name\"],\n",
    "                    \"expected\": test_case[\"expected\"][\"b2\"],\n",
    "                    \"got\": b2,\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Wrong output values for gradient of b2 vector.\\n\\t Expected: {failed_cases[-1].get('expected')} \\n\\tGot: {failed_cases[-1].get('got')}.\"\n",
    "            )\n",
    "\n",
    "    if len(failed_cases) == 0:\n",
    "        print(\"\\033[92m All tests passed\")\n",
    "    else:\n",
    "        print(\"\\033[92m\", successful_cases, \" Tests passed\")\n",
    "        print(\"\\033[91m\", len(failed_cases), \" Tests failed\")\n",
    "\n",
    "    # return failed_cases, len(failed_cases) + successful_cases"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
